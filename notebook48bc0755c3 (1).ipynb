{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:13:13.328105Z",
     "iopub.status.busy": "2025-05-28T03:13:13.327295Z",
     "iopub.status.idle": "2025-05-28T03:13:49.769427Z",
     "shell.execute_reply": "2025-05-28T03:13:49.768479Z",
     "shell.execute_reply.started": "2025-05-28T03:13:13.328073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchainhub langchain-community langchain-chroma google-genai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:13:49.771291Z",
     "iopub.status.busy": "2025-05-28T03:13:49.771049Z",
     "iopub.status.idle": "2025-05-28T03:15:01.039816Z",
     "shell.execute_reply": "2025-05-28T03:15:01.038999Z",
     "shell.execute_reply.started": "2025-05-28T03:13:49.771266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.72.0rc1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.26.4)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (5.29.4)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, qdrant-client\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-2.10.1 qdrant-client-1.14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant-client sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:01.041066Z",
     "iopub.status.busy": "2025-05-28T03:15:01.040787Z",
     "iopub.status.idle": "2025-05-28T03:15:08.327233Z",
     "shell.execute_reply": "2025-05-28T03:15:08.326557Z",
     "shell.execute_reply.started": "2025-05-28T03:15:01.041040Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastembed\n",
      "  Downloading fastembed-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.31.1)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.26.4)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (1.22.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from fastembed) (11.1.0)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
      "  Downloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->fastembed) (2.4.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (5.29.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed) (2025.4.26)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->fastembed) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->fastembed) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->fastembed) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->fastembed) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->fastembed) (2024.2.0)\n",
      "Downloading fastembed-0.7.0-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp311-cp311-manylinux_2_28_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-rust-stemmers, loguru, fastembed\n",
      "Successfully installed fastembed-0.7.0 loguru-0.7.3 py-rust-stemmers-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:08.329550Z",
     "iopub.status.busy": "2025-05-28T03:15:08.329305Z",
     "iopub.status.idle": "2025-05-28T03:15:35.835045Z",
     "shell.execute_reply": "2025-05-28T03:15:35.834278Z",
     "shell.execute_reply.started": "2025-05-28T03:15:08.329527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 03:15:21.511538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748402121.693146      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748402121.745655      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from uuid import uuid4\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors.embeddings_filter import EmbeddingsFilter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:35.836116Z",
     "iopub.status.busy": "2025-05-28T03:15:35.835862Z",
     "iopub.status.idle": "2025-05-28T03:15:35.839748Z",
     "shell.execute_reply": "2025-05-28T03:15:35.839078Z",
     "shell.execute_reply.started": "2025-05-28T03:15:35.836091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:35.840789Z",
     "iopub.status.busy": "2025-05-28T03:15:35.840597Z",
     "iopub.status.idle": "2025-05-28T03:15:36.268674Z",
     "shell.execute_reply": "2025-05-28T03:15:36.267816Z",
     "shell.execute_reply.started": "2025-05-28T03:15:35.840775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fastembed import SparseTextEmbedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:36.269750Z",
     "iopub.status.busy": "2025-05-28T03:15:36.269522Z",
     "iopub.status.idle": "2025-05-28T03:15:36.287103Z",
     "shell.execute_reply": "2025-05-28T03:15:36.286515Z",
     "shell.execute_reply.started": "2025-05-28T03:15:36.269734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create collection\n",
    "qdrant.create_collection(\n",
    "    collection_name=\"demo_collection\",\n",
    "    vectors_config= {\n",
    "        'dense': models.VectorParams(size=768, distance=models.Distance.COSINE)\n",
    "    },\n",
    "    sparse_vectors_config= { 'sparse': models.SparseVectorParams(modifier=models.Modifier.IDF)}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:36.288646Z",
     "iopub.status.busy": "2025-05-28T03:15:36.287913Z",
     "iopub.status.idle": "2025-05-28T03:15:44.344804Z",
     "shell.execute_reply": "2025-05-28T03:15:44.344087Z",
     "shell.execute_reply.started": "2025-05-28T03:15:36.288628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ed28ddaa0d4d0db9a71d4cb8cd3281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8b37f4d82473da58b175bb6b0ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc9e382107d420f8934593e91d4d509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b738fdbfb5b4a0f8959086c0994d227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8742c51c7c54ec6b812ba313f0320ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cbc7d6a09e4235ad0e42aa56d8b6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b940bba14e04fb489c41a37d4880c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cd17bba7ad48dda63347ad595294a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1f6f586cf54281b6970ec61f8c2653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48653c7c97f4488aba7807b6adbf953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04085da4b8bd4faeaa12f2914805ee0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8704a12a7614f5ba2bc89044544aefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfe56571b004b32943610a581a98967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french.txt:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bddddd5db84cff8c9e71f648a31814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dutch.txt:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c55473d8c340c083f2e1f45d7b4aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "danish.txt:   0%|          | 0.00/424 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e111c394004dc6a125037d7149cd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "german.txt:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fd38b2c0484c30b62976f22c5503cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "finnish.txt:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb5de20f3cf48d7b58eaa7b2ed96a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a9060c99e14dd78375d1c3406a925c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "arabic.txt:   0%|          | 0.00/6.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bbc29b01ed4a7b856aab7f7dd8b135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "english.txt:   0%|          | 0.00/936 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a62259539344616b8a05183b1c60866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "romanian.txt:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9055809a32f94d18af099264bc87b0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norwegian.txt:   0%|          | 0.00/851 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e84b0553644c5a968874b8a91a15c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spanish.txt:   0%|          | 0.00/2.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e13f9e04a584590942b7b72835c7ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "portuguese.txt:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9256509eb240cd80ffac7361dbb89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "italian.txt:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a112320a80464c89ccc1b16e4c772e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "russian.txt:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffd53a66bf84c07bc1580e803835c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "greek.txt:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec434003e104c7f8835d0450cafb43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hungarian.txt:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2713e8f3d7f4b36a222be545b7a203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "swedish.txt:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebada83b7bcc4f4a9befe8fb8b13609a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "turkish.txt:   0%|          | 0.00/260 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dense_embedding_model = TextEmbedding(\"BAAI/bge-base-en-v1.5\")\n",
    "dense_embedding_model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\").to('cuda')\n",
    "bm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:44.345720Z",
     "iopub.status.busy": "2025-05-28T03:15:44.345527Z",
     "iopub.status.idle": "2025-05-28T03:15:44.350285Z",
     "shell.execute_reply": "2025-05-28T03:15:44.349647Z",
     "shell.execute_reply.started": "2025-05-28T03:15:44.345705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def embedding_func(documents):\n",
    "    if not isinstance(documents, list):\n",
    "        documents = [documents]\n",
    "\n",
    "    dense_embedding = list(dense_embedding_model.encode(documents))\n",
    "    # dense_embedding = list(dense_embedding_model.embed(documents))\n",
    "    sparse_embedding = list(bm25_embedding_model.embed(documents))\n",
    "\n",
    "    dense_embedding = [list(embd) for embd in dense_embedding]\n",
    "\n",
    "    return {\n",
    "        'dense_embedding' : dense_embedding,\n",
    "        'sparse_embedding' : sparse_embedding\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:44.354032Z",
     "iopub.status.busy": "2025-05-28T03:15:44.353774Z",
     "iopub.status.idle": "2025-05-28T03:15:44.787383Z",
     "shell.execute_reply": "2025-05-28T03:15:44.786614Z",
     "shell.execute_reply.started": "2025-05-28T03:15:44.354017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a4692c65b944f59613f166a27856be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb = embedding_func(['Who is the boss of Apple', 'I am Optimus Prime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:44.788607Z",
     "iopub.status.busy": "2025-05-28T03:15:44.788394Z",
     "iopub.status.idle": "2025-05-28T03:15:46.878214Z",
     "shell.execute_reply": "2025-05-28T03:15:46.877700Z",
     "shell.execute_reply.started": "2025-05-28T03:15:44.788592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e828b64436d14a6dae9f981535b12f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d53ee78f5624ee194adbbef249aa0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "corpus.json:   0%|          | 0.00/6.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf38a5c3f7ec407e82f32829430a4525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/609 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load corpus (list of dicts with keys like 'text', 'title', etc.)\n",
    "from datasets import load_dataset\n",
    "\n",
    "corpus_data = load_dataset(\"yixuantt/MultiHopRAG\", \"corpus\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:46.879171Z",
     "iopub.status.busy": "2025-05-28T03:15:46.878927Z",
     "iopub.status.idle": "2025-05-28T03:15:46.884224Z",
     "shell.execute_reply": "2025-05-28T03:15:46.883298Z",
     "shell.execute_reply.started": "2025-05-28T03:15:46.879145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'author', 'published_at', 'body', 'title', 'url', 'source'],\n",
       "    num_rows: 609\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:15:46.885322Z",
     "iopub.status.busy": "2025-05-28T03:15:46.885054Z",
     "iopub.status.idle": "2025-05-28T03:17:39.413872Z",
     "shell.execute_reply": "2025-05-28T03:17:39.413356Z",
     "shell.execute_reply.started": "2025-05-28T03:15:46.885306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9169da433d244462bf608389c1ba7fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca2ec44eff640e195145febc3f3800f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a09237472724ea98aa712522f3acd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aaccf34bd941f980d4ad7142cf2285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebf13ba023a43a2aa9baa88cdc6a3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81ccab111534f239f5214cbebda4fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b4807a7b7c4092adc124b00d59b790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f79e58874eb48a3812a243fd0c8b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed63fe9b659e45439b526ebc8c773362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d58d0787ff40239caf7780746527d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1939a35deb7c4303bda3b44df69dddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc009660c4364256b1680eec63c6b4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcea6c211674651a1890b6adec6d900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf5688834894598ab7c18f4a44b3303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bdbc51e1184baab8de6edc8aebe878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf254a2bfcd4be98172543075d7aa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b77d85c59e7459a9466f782e1c7d90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb138644f3014c0290561d4f7759fa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5860ec4f481743cd8375b6adc57ff28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb4c1846c2d469fbe74c7e2e2fb39e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d36f99a271048119d4e5fca2903c83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4417660569af4dfbb65e9c18e6060d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eef5cda13445dbb19a136eb2c57314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590e23583b6443899a0a30115edcd2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4218c7bf6240c0b26850e8c1a60556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bf975238264d75a98746435f933c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0deeb982f374405889247c620219853e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b743a57eadf34d53aaccd3362f9a608a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cec1bd6e4446a38b6fabc0aa52bfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d1ca9ad5454aa0a592168b4acb858c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c02a7e70d4dafa3e4e4338a42d265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d9e84a0355478db432eaffa5e4cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f049d090f5844ad1b4573f0fd35559e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c113f1626d4d548a2193c81180b62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec067a67504cb480aa225b21c7c244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab6291f6f9a4f908ee4ba5e11cf1fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4524e86a137c4b6e800b6e5041d1b5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f11130ac4d4eb894622eb967d7f4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f933960a704f4508a4fbd65fe0d29c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35630ff66e54dc69c412a14d02e4402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9b5ab4c9444e74916484a429d658fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81d846ab1844779a42d079f94756b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37e49469655436db72b34ecee49a6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe5884c1bf04836b79d18f99efe8e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d14425f451345bba2d511a9c3333b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ed2713081844d3af8cc30642330496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdb347e94e24b39b7d716dcc92a4d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4d8dd826c6473f8ac91c633b99235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608331e386ee4784b9db7c7a57cc54e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624e1c480e234ca2905cc7fd94061453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f5b852510b44148c5c2f67124b1f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fccbcef5a94d628f09b430f4a95dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8daf21d6881432a8461c7a65d2345d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d232161ada430fbe8a2948f1fa5a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460abcf500e44561b19f87b948eb67a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc88f496a7b64c1fbb22772abad9adaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5d3def51ad4ac4b1063d6b77eabf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd15b2cef17497da238f230ac7b59b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a083136445492f97533bbcecd5caaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e9c6133a8447288f44162aecc771dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a618d33aeee49d9b96d1718d20da003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc5074ba2cc4b46abc28fa7a0ebff4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6e574d572b4d86b095292d11ee5f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac54038df494245b3eaed5d40501dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a81ba4697e24a6490e1615528968583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7741b1265864632ab2ea93e00873c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b6515671a94978a6fc96c7b5aceaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b965cb93674a548ff62f4ddab44090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189bddacdf4548f4a9309501d7f4db8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e09d94f74544a78b2fa4689cd2cbafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87265160e484c1582236b4460f887c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbf71fae3684e089ebd935103aa7045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffcbcd6f97b45bdb4750223ba06ed9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe55d6f3a61c484185a4fc745e6621d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544195af8c9746b9be5bdfdf4de3d978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e365701a2ebe49c8948efae5c69e9cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c922d482dc5444a0b85e91e102aeae83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3020e623cd6b48978688d7bc615d3004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd025b40e114169b9f80f03d8629378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4aae93aa6d435681d0249e6c9686bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658a3bf431e24d65a0f8cfc1bf7ba716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6d0bce9be54ac897ae38a93110ecaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8628d0674b478f942135b97070d7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc10ceed0604539a01bb528f9706d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98783fe5820e4618981417eac7879dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97c570b28974e72a67c9e87e8e213a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147a4bf328a04472a97368627799aaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e068381269401eb79fc08562fafcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b7784120c94c89880f5dfe3fed1b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae3f5c402b543bf8fc4f5fe54b7faaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99a851c7dc6430599e9e53d6a204b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eea83b86e1441cea8315edc5c3db52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b042244a854bbca4d00952e4237072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74a79af97f14f21a7178fc1452420d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ad4a0e642a4ce3af31517ed113ee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6c7db5485543e7bd269dc8ba53453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6334bdae0cca4df097ec1494332e058f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b262cb70f50a4e3687603507692dd89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f334ef46854da4b4d8b40d013f5783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca45fba7432f4704a0ea2c7548db27d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d775a4387a5b433393306b88b114e7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef313fa3f0a4117b6a90a23a597ed32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8dce29949249beba1ae9254da1b8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1022afb2c94efdb59f9422705fa7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1077d2dd87e4b46b0c47794f2f098e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163ed0a91d8340e9973529df63236ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7733614d917f4f69ad9ae7fdca4c04d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01cb29b2eeb4b9a8052280b4012167b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6afdf1c9a984e21849840ccaabf70e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf89840dd454aee872dca1f92cde922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa334f78ee34bf1a4342de317192065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d17be56393c436096eb2e34222f9679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff175059ed224ef09f5d258afe00d7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82e64d2a10140378b56c34782b089e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6fe5225ad34f519b88d6fe30676f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cd56d1b61244fe8ea43dcc7cd6593a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a91ed3cbbe442bbcc2d0ae35984f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ceaf49e5454fe79fb5d6a42f607864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e7f29db2a4f22b8ac7df825de91e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7598bc2d82c449ea3b3f2146bb1c518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a57e0cd9574457bf8d7fefc60e1011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ee9d1b1f3c4ab0bd63153bcfd784db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c811f33dbc4ea4aa03c16e52ea03fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57e781f5f1f4a719075c7d04331a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fca3eca93f449209872da2e627a30ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90895ecfea624c058799c2854da41b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a34c6dec324b23a5b41a892ace1b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418ecab6619442649a625b89e9d1bd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from uuid import uuid4\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "# Convert to LangChain Document format and split each doc into chunks\n",
    "points = []\n",
    "documents = []\n",
    "# i = 0\n",
    "\n",
    "BS = 64\n",
    "\n",
    "for doc in corpus_data:\n",
    "    # i += 1\n",
    "    # if i > 100:\n",
    "    #     break\n",
    "    payload = {\n",
    "        \"title\": doc.get(\"title\", \"\"),\n",
    "        \"source\": doc.get(\"source\", \"\"),\n",
    "        \"published_at\": doc.get(\"published_at\", \"\"),\n",
    "    }\n",
    "    # Split the text into chunks\n",
    "    splits = text_splitter.split_text(doc[\"body\"])\n",
    "    # Create a Document object for each chunk\n",
    "    for chunk in splits:\n",
    "        c_payload = payload.copy()\n",
    "        c_payload['text'] = chunk\n",
    "\n",
    "        documents.append(c_payload)\n",
    "\n",
    "\n",
    "for i in range(0, len(documents), BS):\n",
    "\n",
    "    batch = documents[i:i+BS]\n",
    "    embeddings = embedding_func([payload['text'] for payload in batch])\n",
    "    # print(embeddings)\n",
    "\n",
    "    for payload, sparse_embedding, dense_embedding in zip(batch, embeddings['sparse_embedding'], embeddings['dense_embedding']):\n",
    "        points.append(\n",
    "             models.PointStruct(id=int(uuid4()), \n",
    "                                vector={\n",
    "                                    'sparse' : models.SparseVector(**sparse_embedding.as_object()),\n",
    "                                    # 'sparse' : sparse_embedding.as_object(),\n",
    "                                    'dense' : dense_embedding\n",
    "                                }, \n",
    "                                payload=payload)\n",
    "        )\n",
    "    \n",
    "        \n",
    "    # embedding = embedding_model.encode(chunk)\n",
    "    # points.append(\n",
    "    #     models.PointStruct(id=int(uuid4()), vector=embedding.tolist(), payload=c_payload)\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:39.414819Z",
     "iopub.status.busy": "2025-05-28T03:17:39.414558Z",
     "iopub.status.idle": "2025-05-28T03:17:46.377477Z",
     "shell.execute_reply": "2025-05-28T03:17:46.376676Z",
     "shell.execute_reply.started": "2025-05-28T03:17:39.414793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.upsert(collection_name=\"demo_collection\", points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:46.378577Z",
     "iopub.status.busy": "2025-05-28T03:17:46.378280Z",
     "iopub.status.idle": "2025-05-28T03:17:46.383868Z",
     "shell.execute_reply": "2025-05-28T03:17:46.383135Z",
     "shell.execute_reply.started": "2025-05-28T03:17:46.378553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8145"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:46.384878Z",
     "iopub.status.busy": "2025-05-28T03:17:46.384638Z",
     "iopub.status.idle": "2025-05-28T03:17:47.296058Z",
     "shell.execute_reply": "2025-05-28T03:17:47.295518Z",
     "shell.execute_reply.started": "2025-05-28T03:17:46.384857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38177fa04fa4336bc6bfe8240d727de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiHopRAG.json:   0%|          | 0.00/5.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ab1a5e5749411b9db0bbde4ef24966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "query_data = load_dataset(\"yixuantt/MultiHopRAG\", \"MultiHopRAG\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:47.297035Z",
     "iopub.status.busy": "2025-05-28T03:17:47.296816Z",
     "iopub.status.idle": "2025-05-28T03:17:48.002023Z",
     "shell.execute_reply": "2025-05-28T03:17:48.001254Z",
     "shell.execute_reply.started": "2025-05-28T03:17:47.297012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llm'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 318, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
      "remote: Total 318 (delta 55), reused 67 (delta 34), pack-reused 227 (from 1)\u001b[K\n",
      "Receiving objects: 100% (318/318), 63.48 KiB | 2.64 MiB/s, done.\n",
      "Resolving deltas: 100% (194/194), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/hung20gg/llm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:48.003364Z",
     "iopub.status.busy": "2025-05-28T03:17:48.003096Z",
     "iopub.status.idle": "2025-05-28T03:17:51.161960Z",
     "shell.execute_reply": "2025-05-28T03:17:51.160841Z",
     "shell.execute_reply.started": "2025-05-28T03:17:48.003337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:51.164390Z",
     "iopub.status.busy": "2025-05-28T03:17:51.163479Z",
     "iopub.status.idle": "2025-05-28T03:17:53.227016Z",
     "shell.execute_reply": "2025-05-28T03:17:53.226457Z",
     "shell.execute_reply.started": "2025-05-28T03:17:51.164350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from llm import OpenAIWrapper\n",
    "\n",
    "host = \"https://integrate.api.nvidia.com/v1\" # vLLM host\n",
    "model_name = \"qwen/qwen2.5-7b-instruct\"\n",
    "api_key = 'eat-my-ass'\n",
    "\n",
    "llm = OpenAIWrapper(host = host, model_name = model_name, api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:53.227940Z",
     "iopub.status.busy": "2025-05-28T03:17:53.227754Z",
     "iopub.status.idle": "2025-05-28T03:17:53.231839Z",
     "shell.execute_reply": "2025-05-28T03:17:53.231152Z",
     "shell.execute_reply.started": "2025-05-28T03:17:53.227920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"Below is a question followed by some context from different sources. \"\n",
    "    \"Please answer the main question based on the context in <question> tag. The answer to the question is a word or entity. \"\n",
    "    \"If the provided information is sufficient to answer the question, respond 'Yes' and answer the question \"\n",
    "    \"Else, return no and provide new sub-question needed to answer the original question. \\n\\n\"\n",
    "    \"Think step-by-step and return in the following format \\n\\n\"\n",
    "    \"## Reasoning:\\n\"\n",
    "    \"Step-by-step reasoning\\n\"\n",
    "    \"## Decision:\\n\"\n",
    "    \"Yes/No\\n\"\n",
    "    \"## Details:\\n\"\n",
    "    \"Final Answer/New question.\\n\\n\"\n",
    "    \"Note:\\n\"\n",
    "    \"- Do not guess early. Use previous steps and retrieved knowledge to build your reasoning gradually.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:53.233473Z",
     "iopub.status.busy": "2025-05-28T03:17:53.232687Z",
     "iopub.status.idle": "2025-05-28T03:17:53.262598Z",
     "shell.execute_reply": "2025-05-28T03:17:53.261980Z",
     "shell.execute_reply.started": "2025-05-28T03:17:53.233452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseEmbedding(values=array([1], dtype=int32), indices=array([892665534], dtype=int32))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bm25_embedding_model.query_embed('Fuck you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:17:53.263586Z",
     "iopub.status.busy": "2025-05-28T03:17:53.263361Z",
     "iopub.status.idle": "2025-05-28T03:17:53.272050Z",
     "shell.execute_reply": "2025-05-28T03:17:53.271298Z",
     "shell.execute_reply.started": "2025-05-28T03:17:53.263566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def embedding_func_2(documents):\n",
    "    if not isinstance(documents, list):\n",
    "        documents = [documents]\n",
    "\n",
    "    dense_embedding = list(dense_embedding_model.encode(documents))\n",
    "    # dense_embedding = list(dense_embedding_model.embed(documents))\n",
    "    sparse_embedding = list(bm25_embedding_model.embed(documents))\n",
    "\n",
    "    dense_embedding = [list(embd) for embd in dense_embedding]\n",
    "\n",
    "    return {\n",
    "        'dense_embedding' : dense_embedding,\n",
    "        'sparse_embedding' : sparse_embedding\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:19:22.498873Z",
     "iopub.status.busy": "2025-05-28T03:19:22.498148Z",
     "iopub.status.idle": "2025-05-28T03:19:22.504193Z",
     "shell.execute_reply": "2025-05-28T03:19:22.503380Z",
     "shell.execute_reply.started": "2025-05-28T03:19:22.498852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n--------------\\n\".join([doc.payload['text'] for doc in docs])\n",
    "\n",
    "def rag(query, query_filter = None):\n",
    "    query_embedding = embedding_func(query)\n",
    "\n",
    "    prefetch = [\n",
    "        models.Prefetch(\n",
    "            query=query_embedding['dense_embedding'][0],\n",
    "            using=\"dense\",\n",
    "            limit=20,\n",
    "        ),\n",
    "        models.Prefetch(\n",
    "            # query=models.SparseVector(**query_embedding['sparse_embedding'][0].as_object()),\n",
    "            query = query_embedding['sparse_embedding'][0].as_object(),\n",
    "            using=\"sparse\",\n",
    "            limit=20,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    search_results = qdrant.query_points(\n",
    "        collection_name=\"demo_collection\",\n",
    "        query=models.FusionQuery(\n",
    "            fusion=models.Fusion.RRF  # we are using reciprocal rank fusion here\n",
    "        ),\n",
    "        prefetch=prefetch,\n",
    "        query_filter=query_filter,\n",
    "        limit=5\n",
    "    ).points\n",
    "\n",
    "    return format_docs(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:19:22.752565Z",
     "iopub.status.busy": "2025-05-28T03:19:22.751992Z",
     "iopub.status.idle": "2025-05-28T03:19:22.942852Z",
     "shell.execute_reply": "2025-05-28T03:19:22.941678Z",
     "shell.execute_reply.started": "2025-05-28T03:19:22.752544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42e982d4f4146be8d6f81c8dd636bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'What’s up with Tesla’s Cybertruck? Everything to know about the much-hyped electric pickup\\n\\nAfter four years, the long-awaited launch of the Tesla Cybertruck electric pickup has come and gone.\\n\\nThe boxy vehicle is Tesla’s first new model since 2020, when it started delivering the Model Y. Yet, Cybertruck’s initial debut predates that moment; Tesla CEO Elon Musk showed off an early version of the pickup at a memorable 2019 event, when it accidentally smashed two windows while attempting to demonstrate Cybertruck’s durability.\\n\\nHere we’ll answer some questions we figured a brave explorer such as yourself might ask (err… type in a search bar) about Tesla’s Cybertruck, including details on the vehicle’s specs, availability and design of the vehicle. The first deliveries, in which about 10 high-profile customers like Reddit co-founder Alexis Ohanian took possession of the truck, occurred November 30 at the Tesla Gigafactory in Austin.\\n--------------\\nIn late 2017, Musk hatched a plan to wrest control of the lab from Altman and the other founders and transform it into a commercial operation that would join forces with Tesla and rely on supercomputers the car company was developing, according to four people familiar with the matter. When Altman and others pushed back, Musk quit and said he would focus on his own AI work at Tesla. In February 2018, he announced his departure to OpenAI’s staff on the top floor of the startup’s offices in a converted truck factory, three people who attended the meeting said. When he said that OpenAI needed to move faster, one researcher retorted at the meeting that Musk was being reckless. Musk called the researcher a “jackass” and stormed out, taking his deep pockets with him. OpenAI suddenly needed new financing in a hurry. Altman flew to Sun Valley for a conference and ran into Satya Nadella, Microsoft’s CEO. A tie-up seemed natural. Altman knew Microsoft’s chief technology officer, Kevin Scott.\\n--------------\\nNio has opened its 2,000th Power Swap Station in China, nearing its goal to build 2,300 stations by the end of 2023. The company has expanded on its strategy of swapping out EV batteries, rather than charging them, an infrastructure-intensive process that has the potential to make topping up a battery as quick as filling up a gas tank.\\n\\nTesla has the attention of the U.S. Department of Justice — again. This time it has received requests for information, including subpoenas from the DOJ related to perks, the advertised range of its EVs and personnel decisions.\\n\\nIn-car and mobile tech\\n--------------\\nAmong EVs, vehicles with smaller batteries are generally better for the environment.\\n\\nStay tuned\\n\\nWe have a lot more questions and we expect Tesla to share more details during its November 30 delivery event. How does the Cybertruck compare to other Teslas? What about electric pickups from the competition, including Ford or GMC? When will Tesla release the cheaper, single-motor Cybertruck variant it promised back in 2019? Check back for updates as we learn more.\\n--------------\\nTesla CEO Elon Musk is also trying to build a humanoid, called Optimus, through the electric car-maker’s robotics division, but a hyped-up live demonstration last year of the robot’s awkwardly halting steps didn’t impress experts in the robotics field. Seemingly farther along is Tesla’s Austin, Texas-based neighbor Apptronik, which unveiled its Apollo humanoid in an August video demonstration.\\n\\nAll the attention — and money — poured into making ungainly humanoid machines might make the whole enterprise seem like a futile hobby for wealthy technologists, but for some pioneers of legged robots it’s all about what you learn along the way.\\n\\n“Not only about their design and operation, but also about how people respond to them, and about the critical underlying technologies for mobility, dexterity, perception and intelligence,” said Marc Raibert, the co-founder of Boston Dynamics, best known for its dog-like robots named Spot.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('Who is the boss of Tesla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:19:23.382237Z",
     "iopub.status.busy": "2025-05-28T03:19:23.381757Z",
     "iopub.status.idle": "2025-05-28T03:19:23.386913Z",
     "shell.execute_reply": "2025-05-28T03:19:23.386350Z",
     "shell.execute_reply.started": "2025-05-28T03:19:23.382213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2556"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:19:23.778197Z",
     "iopub.status.busy": "2025-05-28T03:19:23.777560Z",
     "iopub.status.idle": "2025-05-28T03:19:23.783400Z",
     "shell.execute_reply": "2025-05-28T03:19:23.782468Z",
     "shell.execute_reply.started": "2025-05-28T03:19:23.778174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_decision(response):\n",
    "\n",
    "    decision = False\n",
    "    detail = ''\n",
    "    \n",
    "    if '## Decision:' in response and '## Details:' in response:\n",
    "        decision_text = response.split('## Decision:')[1].split('## Details:' )[0]\n",
    "        detail = response.split('## Details:' )[1]\n",
    "\n",
    "        if 'yes' in decision_text.lower():\n",
    "            decision = True\n",
    "        else:\n",
    "            decision = False\n",
    "\n",
    "    return decision, detail\n",
    "\n",
    "\n",
    "def force_answer(llm, query, rag_content):\n",
    "\n",
    "    messages =[\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content': f'<question>{query}</question> <content>{rag_content}<context>. Based on the given context, think step-by-step and return your answer in \\\\boxed{{}}. DONOT return no'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:19:25.856479Z",
     "iopub.status.busy": "2025-05-28T03:19:25.856184Z",
     "iopub.status.idle": "2025-05-28T03:19:25.863169Z",
     "shell.execute_reply": "2025-05-28T03:19:25.862446Z",
     "shell.execute_reply.started": "2025-05-28T03:19:25.856458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def solve(llm, query, max_iter = 3):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'system',\n",
    "            'content': system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'decoy'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    decision = False\n",
    "    final_answer = ''\n",
    "    intermediate_question = query\n",
    "\n",
    "    rag_content = ''\n",
    "    response = 'Anw cut'\n",
    "    \n",
    "    for i in range(3):\n",
    "        # remove prev\n",
    "        messages.pop()\n",
    "\n",
    "        rag_content += rag(intermediate_question)\n",
    "        \n",
    "        content = f\"Here is the provided content: \\n\\n {rag_content}. Answer the followning question \\n\\n<question>\\n\\n{query}\\n\\n</question>\"\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                'role' : 'user',\n",
    "                'content': content\n",
    "            }\n",
    "        )\n",
    "\n",
    "        response = llm(messages)\n",
    "        \n",
    "        print('### =================', i + 1, '================ ###')\n",
    "        print(response)\n",
    "        print('### ===================================== ###')\n",
    "        \n",
    "        decision, detail = get_decision(response)\n",
    "\n",
    "        # messages.append(\n",
    "        #     {\n",
    "        #         'role':'assistant',\n",
    "        #         'content': response\n",
    "        #     }\n",
    "        # )\n",
    "        \n",
    "\n",
    "        intermediate_question = detail\n",
    "        if decision:\n",
    "            break\n",
    "        \n",
    "\n",
    "    # messages.pop()\n",
    "    # messages.pop()\n",
    "    \n",
    "    # messages.append(\n",
    "    #     {\n",
    "    #         'role' :'assistant',\n",
    "    #         'content' : response\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    answer = force_answer(llm, query, rag_content)\n",
    "\n",
    "    print('### =================RAG================ ###')\n",
    "    print(rag_content)\n",
    "    print('### ===================================== ###')\n",
    "    \n",
    "\n",
    "    print('### =================Final================ ###')\n",
    "    print(answer)\n",
    "    print('### ===================================== ###')\n",
    "    \n",
    "    return answer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T03:21:17.532480Z",
     "iopub.status.busy": "2025-05-28T03:21:17.531766Z",
     "iopub.status.idle": "2025-05-28T03:21:26.480924Z",
     "shell.execute_reply": "2025-05-28T03:21:26.480182Z",
     "shell.execute_reply.started": "2025-05-28T03:21:17.532454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1e546382004b90904316bf9fd769a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=105, prompt_tokens=1136, total_tokens=1241, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "### ================= 1 ================ ###\n",
      "## Reasoning:\n",
      "The provided context does not explicitly mention the current CEO of Tesla. However, given that Elon Musk is a central figure in the information provided, and considering he is the founder of Tesla, it is likely he is still the CEO. The context does not provide any information suggesting his position has changed.\n",
      "\n",
      "## Decision:\n",
      "No\n",
      "## Details:\n",
      "A new sub-question needed to answer the original question is: \"Who is currently the CEO of Tesla?\"\n",
      "\n",
      "Final Answer/New question: Who is currently the CEO of Tesla?\n",
      "### ===================================== ###\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f9b654ea54c6fbb288b973582a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=95, prompt_tokens=1992, total_tokens=2087, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "### ================= 2 ================ ###\n",
      "## Reasoning:\n",
      "The provided context does not explicitly state who the CEO of Tesla is. However, it does mention Elon Musk in the context of Tesla and its projects, but it does not confirm if he is still the CEO.\n",
      "## Decision:\n",
      "No\n",
      "## Details:\n",
      "To answer the question \"Who is the CEO of Tesla?\", we need to know if Elon Musk is still the CEO or if there have been any changes in leadership since the last update in the provided context.\n",
      "### ===================================== ###\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0f9638631a4b71abf9240e60ad0bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=102, prompt_tokens=2826, total_tokens=2928, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "### ================= 3 ================ ###\n",
      "## Reasoning:\n",
      "Step-by-step reasoning\n",
      "1. The context provided discusses various events related to OpenAI and Tesla but does not directly state the current CEO of Tesla.\n",
      "2. The question asks specifically for the current CEO of Tesla.\n",
      "3. The information given does not mention any current CEO.\n",
      "## Decision:\n",
      "No\n",
      "## Details:\n",
      "To answer the question \"Who is the CEO of Tesla?\", we need the current CEO of Tesla mentioned in the context.\n",
      "New question: Who is the current CEO of Tesla?\n",
      "### ===================================== ###\n",
      "CompletionUsage(completion_tokens=13, prompt_tokens=2724, total_tokens=2737, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "### =================RAG================ ###\n",
      "In late 2017, Musk hatched a plan to wrest control of the lab from Altman and the other founders and transform it into a commercial operation that would join forces with Tesla and rely on supercomputers the car company was developing, according to four people familiar with the matter. When Altman and others pushed back, Musk quit and said he would focus on his own AI work at Tesla. In February 2018, he announced his departure to OpenAI’s staff on the top floor of the startup’s offices in a converted truck factory, three people who attended the meeting said. When he said that OpenAI needed to move faster, one researcher retorted at the meeting that Musk was being reckless. Musk called the researcher a “jackass” and stormed out, taking his deep pockets with him. OpenAI suddenly needed new financing in a hurry. Altman flew to Sun Valley for a conference and ran into Satya Nadella, Microsoft’s CEO. A tie-up seemed natural. Altman knew Microsoft’s chief technology officer, Kevin Scott.\n",
      "--------------\n",
      "What’s up with Tesla’s Cybertruck? Everything to know about the much-hyped electric pickup\n",
      "\n",
      "After four years, the long-awaited launch of the Tesla Cybertruck electric pickup has come and gone.\n",
      "\n",
      "The boxy vehicle is Tesla’s first new model since 2020, when it started delivering the Model Y. Yet, Cybertruck’s initial debut predates that moment; Tesla CEO Elon Musk showed off an early version of the pickup at a memorable 2019 event, when it accidentally smashed two windows while attempting to demonstrate Cybertruck’s durability.\n",
      "\n",
      "Here we’ll answer some questions we figured a brave explorer such as yourself might ask (err… type in a search bar) about Tesla’s Cybertruck, including details on the vehicle’s specs, availability and design of the vehicle. The first deliveries, in which about 10 high-profile customers like Reddit co-founder Alexis Ohanian took possession of the truck, occurred November 30 at the Tesla Gigafactory in Austin.\n",
      "--------------\n",
      "Tesla CEO Elon Musk is also trying to build a humanoid, called Optimus, through the electric car-maker’s robotics division, but a hyped-up live demonstration last year of the robot’s awkwardly halting steps didn’t impress experts in the robotics field. Seemingly farther along is Tesla’s Austin, Texas-based neighbor Apptronik, which unveiled its Apollo humanoid in an August video demonstration.\n",
      "\n",
      "All the attention — and money — poured into making ungainly humanoid machines might make the whole enterprise seem like a futile hobby for wealthy technologists, but for some pioneers of legged robots it’s all about what you learn along the way.\n",
      "\n",
      "“Not only about their design and operation, but also about how people respond to them, and about the critical underlying technologies for mobility, dexterity, perception and intelligence,” said Marc Raibert, the co-founder of Boston Dynamics, best known for its dog-like robots named Spot.\n",
      "--------------\n",
      "OpenAI started out as a nonprofit when it launched with financial backing from Tesla CEO Elon Musk and others. Its stated aims were to “advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.”\n",
      "\n",
      "That changed in 2018 when it incorporated a for-profit business Open AI LP, and shifted nearly all its staff into the business, not long after releasing its first generation of the GPT large language model for mimicking human writing. Around the same time, Musk, who had co-chaired its board with Altman, resigned from the board in a move that OpenAI said would eliminate a “potential future conflict for Elon” due to Tesla’s work on building self-driving systems.\n",
      "\n",
      "While OpenAI’s board has preserved its nonprofit governance structure, the startup it oversees has increasingly sought to capitalize on its technology by tailoring its popular chatbot to business customers.\n",
      "--------------\n",
      "The 'whistleblower'\n",
      "\n",
      "Clark's first quarterly board meeting as sole CEO was June 1. His second was Aug. 31, days before he was forced out. The board was made up largely of investors who were betting on the founder. It included Founders Fund's Trae Stephens, who had helped start defense-tech firm Anduril Industries, and Michael Ronen, who left SoftBank in 2020. Andreessen Horowitz was represented by Bob Swan, an operating partner at the firm and former CEO of Intel .\n",
      "\n",
      "Bob Swan, then-interim chief executive officer and chief financial officer of Intel Corp., reacts during the inauguration of the company's research and development facility in Bengaluru, India, on November 15, 2018. Samyukta Lakshmi | Bloomberg | Getty ImagesSo the Epic Games Store isn’t a games store, right? It’s the store operated by Epic Games. So we have a lot of non-games there already. We have the Brave web browser, we have a number of software creation tools including Unreal Engine, and there’s more coming, including some other awesome creation tools and productivity tools. We’ll host any app anybody wants of any sort.\n",
      "\n",
      "I think the gaming market is something we’re uniquely close to, and so I think we would likely be able to forge closer partnerships and opportunities in gaming, but we’ll be open to everybody on Android as we are on PC.\n",
      "\n",
      "What were your settlement talks with Google CEO Sundar Pichai like?\n",
      "--------------\n",
      "What’s up with Tesla’s Cybertruck? Everything to know about the much-hyped electric pickup\n",
      "\n",
      "After four years, the long-awaited launch of the Tesla Cybertruck electric pickup has come and gone.\n",
      "\n",
      "The boxy vehicle is Tesla’s first new model since 2020, when it started delivering the Model Y. Yet, Cybertruck’s initial debut predates that moment; Tesla CEO Elon Musk showed off an early version of the pickup at a memorable 2019 event, when it accidentally smashed two windows while attempting to demonstrate Cybertruck’s durability.\n",
      "\n",
      "Here we’ll answer some questions we figured a brave explorer such as yourself might ask (err… type in a search bar) about Tesla’s Cybertruck, including details on the vehicle’s specs, availability and design of the vehicle. The first deliveries, in which about 10 high-profile customers like Reddit co-founder Alexis Ohanian took possession of the truck, occurred November 30 at the Tesla Gigafactory in Austin.\n",
      "--------------\n",
      "In late 2017, Musk hatched a plan to wrest control of the lab from Altman and the other founders and transform it into a commercial operation that would join forces with Tesla and rely on supercomputers the car company was developing, according to four people familiar with the matter. When Altman and others pushed back, Musk quit and said he would focus on his own AI work at Tesla. In February 2018, he announced his departure to OpenAI’s staff on the top floor of the startup’s offices in a converted truck factory, three people who attended the meeting said. When he said that OpenAI needed to move faster, one researcher retorted at the meeting that Musk was being reckless. Musk called the researcher a “jackass” and stormed out, taking his deep pockets with him. OpenAI suddenly needed new financing in a hurry. Altman flew to Sun Valley for a conference and ran into Satya Nadella, Microsoft’s CEO. A tie-up seemed natural. Altman knew Microsoft’s chief technology officer, Kevin Scott.\n",
      "--------------\n",
      "We probably won’t know the full truth on this for a long time, as the characters in the drama are likely to be NDA’ed up. Per various whispers and leaks, an all-hands meeting about the situation this afternoon didn’t produce any revelations beyond banal reassurances that the company is fine and they’ll get a fresh CEO soon. Expect to hear a lot of rumors before we hear the real thing.\n",
      "--------------\n",
      "The Steam Deck OLED delivers on Valve’s original promise\n",
      "\n",
      "OLED is in the name for a reason.\n",
      "\n",
      "The OLED panel in the new Steam Deck is lighter, thinner, and more power efficient than its LCD predecessor. It’s also bigger and faster. Though the device has the same shape as the original Steam Deck, smaller screen bezels allow for a display that’s slightly larger, at 7.4 inches compared to 7 inches. The panel has a wider color gamut (110% DCI-P3, for the visual obsessives) and the beautiful, inky blacks that OLED dorks like myself adore.\n",
      "\n",
      "Steam Deck OLED’s bigger, better battery Valve’s promise of 30-50% more battery raised one obvious question: Is that comparing the OLED model with a Steam Deck running its original firmware (which had poor battery life), or a Steam Deck using the latest firmware? Valve’s answer: the latter! So if you’re a Steam Deck owner, expect those big battery improvements over your current Steam Deck experience.In late 2017, Musk hatched a plan to wrest control of the lab from Altman and the other founders and transform it into a commercial operation that would join forces with Tesla and rely on supercomputers the car company was developing, according to four people familiar with the matter. When Altman and others pushed back, Musk quit and said he would focus on his own AI work at Tesla. In February 2018, he announced his departure to OpenAI’s staff on the top floor of the startup’s offices in a converted truck factory, three people who attended the meeting said. When he said that OpenAI needed to move faster, one researcher retorted at the meeting that Musk was being reckless. Musk called the researcher a “jackass” and stormed out, taking his deep pockets with him. OpenAI suddenly needed new financing in a hurry. Altman flew to Sun Valley for a conference and ran into Satya Nadella, Microsoft’s CEO. A tie-up seemed natural. Altman knew Microsoft’s chief technology officer, Kevin Scott.\n",
      "--------------\n",
      "What’s up with Tesla’s Cybertruck? Everything to know about the much-hyped electric pickup\n",
      "\n",
      "After four years, the long-awaited launch of the Tesla Cybertruck electric pickup has come and gone.\n",
      "\n",
      "The boxy vehicle is Tesla’s first new model since 2020, when it started delivering the Model Y. Yet, Cybertruck’s initial debut predates that moment; Tesla CEO Elon Musk showed off an early version of the pickup at a memorable 2019 event, when it accidentally smashed two windows while attempting to demonstrate Cybertruck’s durability.\n",
      "\n",
      "Here we’ll answer some questions we figured a brave explorer such as yourself might ask (err… type in a search bar) about Tesla’s Cybertruck, including details on the vehicle’s specs, availability and design of the vehicle. The first deliveries, in which about 10 high-profile customers like Reddit co-founder Alexis Ohanian took possession of the truck, occurred November 30 at the Tesla Gigafactory in Austin.\n",
      "--------------\n",
      "So the Epic Games Store isn’t a games store, right? It’s the store operated by Epic Games. So we have a lot of non-games there already. We have the Brave web browser, we have a number of software creation tools including Unreal Engine, and there’s more coming, including some other awesome creation tools and productivity tools. We’ll host any app anybody wants of any sort.\n",
      "\n",
      "I think the gaming market is something we’re uniquely close to, and so I think we would likely be able to forge closer partnerships and opportunities in gaming, but we’ll be open to everybody on Android as we are on PC.\n",
      "\n",
      "What were your settlement talks with Google CEO Sundar Pichai like?\n",
      "--------------\n",
      "OpenAI started out as a nonprofit when it launched with financial backing from Tesla CEO Elon Musk and others. Its stated aims were to “advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.”\n",
      "\n",
      "That changed in 2018 when it incorporated a for-profit business Open AI LP, and shifted nearly all its staff into the business, not long after releasing its first generation of the GPT large language model for mimicking human writing. Around the same time, Musk, who had co-chaired its board with Altman, resigned from the board in a move that OpenAI said would eliminate a “potential future conflict for Elon” due to Tesla’s work on building self-driving systems.\n",
      "\n",
      "While OpenAI’s board has preserved its nonprofit governance structure, the startup it oversees has increasingly sought to capitalize on its technology by tailoring its popular chatbot to business customers.\n",
      "--------------\n",
      "We probably won’t know the full truth on this for a long time, as the characters in the drama are likely to be NDA’ed up. Per various whispers and leaks, an all-hands meeting about the situation this afternoon didn’t produce any revelations beyond banal reassurances that the company is fine and they’ll get a fresh CEO soon. Expect to hear a lot of rumors before we hear the real thing.\n",
      "### ===================================== ###\n",
      "### =================Final================ ###\n",
      "\\boxed{Elon Musk} is the CEO of Tesla.\n",
      "### ===================================== ###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\boxed{Elon Musk} is the CEO of Tesla.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(llm, 'Who is the CEO of Tesla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:37:15.644348Z",
     "iopub.status.busy": "2025-05-27T13:37:15.644098Z",
     "iopub.status.idle": "2025-05-27T13:37:15.647721Z",
     "shell.execute_reply": "2025-05-27T13:37:15.646983Z",
     "shell.execute_reply.started": "2025-05-27T13:37:15.644330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# answer = response.split(\"Answer is:\")[1].strip()[:-1]\n",
    "# answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-27T13:30:36.073346Z",
     "iopub.status.idle": "2025-05-27T13:30:36.073649Z",
     "shell.execute_reply": "2025-05-27T13:30:36.073502Z",
     "shell.execute_reply.started": "2025-05-27T13:30:36.073493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "\n",
    "    if '\\\\boxed{' in text:\n",
    "        text = text.split('\\\\boxed{')[1].split('}')[0]\n",
    "    else:\n",
    "        text = text.split('\\n')[-1]\n",
    "    \n",
    "    return re.sub(r\"[\\W_]+\", \"\", text.lower())\n",
    "\n",
    "test_count = 1\n",
    "match = 0\n",
    "preds = []\n",
    "labels = []\n",
    "iteration_logs = []\n",
    "\n",
    "for i in range(test_count):\n",
    "    query = query_data[i][\"query\"]\n",
    "    gold = query_data[i][\"answer\"]\n",
    "\n",
    "    result = ircot_answer(query)\n",
    "    pred = result[\"answer\"]\n",
    "    pred_norm = normalize_text(pred)\n",
    "    gold_norm = normalize_text(gold)\n",
    "\n",
    "#     if pred_norm == gold_norm:\n",
    "#         match += 1\n",
    "\n",
    "#     preds.append(pred_norm)\n",
    "#     labels.append(gold_norm)\n",
    "#     iteration_logs.append(result[\"iterations\"])\n",
    "\n",
    "# accuracy = match / test_count * 100\n",
    "# f1 = f1_score(labels, preds, average='micro')\n",
    "# precision = precision_score(labels, preds, average='micro')\n",
    "# recall = recall_score(labels, preds, average='micro')\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "# print(f\"F1 Score: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "# print(f\"Avg IRCoT iterations: {sum(iteration_logs)/len(iteration_logs):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
